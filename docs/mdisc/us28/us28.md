# US28: Analysis of Shortest Route Feature

**As a Product Owner, I want to conclude about the efficiency of the above procedure, by analysing the worst-case time complexity.**

## Purpose
This document provides a detailed analysis of the computational efficiency of the shortest route feature. Computational efficiency measures how well an algorithm uses resources (primarily time and memory) as the size of the problem it solves grows. The main objective is to determine the **worst-case time complexity**, which represents the maximum amount of time the algorithm could potentially take for any given input of a specific size. This is crucial for a Product Owner to understand the performance limits and scalability of the feature, especially under demanding conditions. This analysis focuses solely on the computational steps of the algorithms and **excludes any procedures related to graphic visualization**.

### Legend for Analysis Column

In the "ANALYSIS" column of the following tables, specific variables and notations are used to describe the components of time complexity. These counts provide a detailed breakdown of the computational work involved in each step of an algorithm.

- **$n$ (Number of Stations/Vertices):**
  This variable represents the **total count of individual points** (often called "nodes" or "vertices") within the entire graph or network being analyzed. In real-world scenarios, these could represent train stations, cities, or key locations. It indicates the overall size of the network being processed.

- **$m$ (Number of Connections/Edges):**
  This variable denotes the **total count of direct links or connections** (referred to as "edges") between the stations in the graph. For instance, a road connecting two cities or a railway line between stations would be an edge. It signifies how interconnected or "dense" the graph is.

- **$k$ (Number of Required Stations):**
  This variable specifically refers to the **number of distinct stations that a particular route must visit in a predefined sequence**. For example, if a journey requires stops at points A, B, and C in that exact order, then $k=3$. It's important to note that the value of $k$ can never exceed the total number of stations in the graph, so $k \le n$.

- **$\mathcal{O}(\text{expression})$ (Big O Notation):**
  This is a widely adopted mathematical notation used to describe the **upper bound of an algorithm's time complexity**. It provides a simplified way to understand how the algorithm's runtime grows as the size of its input (represented by $n$, $m$, and $k$) increases, particularly in the worst-case scenario. Big O notation focuses on the most significant term that dictates the growth rate and deliberately ignores constant factors and less impactful terms. This is because, for very large inputs, the dominant term is what truly determines performance, while constants and lower-order terms become negligible. For example, an algorithm with $\mathcal{O}(n^2)$ complexity will become significantly slower than an $\mathcal{O}(n)$ algorithm as $n$ gets larger, even if the $\mathcal{O}(n^2)$ algorithm has a smaller constant factor initially.

### Explanation for Analysis Column

* **Counting Operations ($A$, $C$, $L$, $Op$, $R$):** These granular counts (assignments, comparisons, lookups, general operations, returns) are fundamental to deriving the total number of operations.  "Complexidade de algoritmos", each primitive operation is assumed to take a constant amount of time. By summing these up for each line of code, we estimate the total operations.

* **Loops and Sums ($\sum$):** When an algorithm involves loops, the total number of operations is often expressed as a summation. For instance, a `for` loop running `N` times with a constant number of operations inside translates to $\sum_{i=1}^{N} \mathcal{O}(1) = \mathcal{O}(N)$ total operations. 

---

## Algorithms Used

This section details the primary algorithms employed in the shortest route feature and their individual worst-case time complexities. Understanding these complexities is vital for predicting how the feature will perform under various conditions and for identifying potential performance bottlenecks.

### 1. Multi-Stage Ordered Shortest Path Algorithm

*This algorithm is designed to find a path that traverses a specific list of stations in a predefined order. It tackles this complex problem by breaking it down into a series of smaller, more manageable sub-problems. Essentially, it repeatedly calls a standard "Single-Source Shortest Path" algorithm (commonly Dijkstra's algorithm) to find the optimal route between each consecutive pair of stations in the required list. Once all these individual optimal sub-paths are found, they are seamlessly combined to form the final, complete route, ensuring that each segment is the shortest possible.*


| **CODE** | **ANALYSIS** |
|---|---|
| `function multiStageOrderedShortestPath(graph, requiredStations)` | **$\mathcal{O}(k(n + m) \log n)$** |
| `    if requiredStations.size < 2:` | $1C$ |
| `        return null` | $1R$ |
| `    for each station in requiredStations:` | $(k+1)C$ |
| `        if station not in graph:` | $k \cdot (L+C)$ |
| `            return null` | $1R$ |
| `    fullPath = []` | $1A$ |
| `    for i from 0 to requiredStations.size - 2:` | $(k-1+1)C$ |
| `        segment = singleSourceShortestPath(graph, requiredStations[i], requiredStations[i+1])` | $(k-1) \cdot \mathcal{O}((n+m)\log n)$ |
| `        if segment is null:` | $(k-1)C$ |
| `            return null` | $1R$ |
| `        if i < requiredStations.size - 2:` | $(k-1)C$ |
| `            fullPath.addAll(segment[0 to segment.size - 2])` | $\leq (k-1) \cdot \mathcal{O}(n)$ |
| `        else:` | $(k-1)C$ |
| `            fullPath.addAll(segment)` | $\leq (k-1) \cdot \mathcal{O}(n)$ |
| `    return fullPath` | $1R$ |

### Worst-Case Time Complexity

The overall execution time of the `multiStageOrderedShortestPath` function is predominantly determined by the number of times it invokes the `singleSourceShortestPath` algorithm (which, in this context, refers to Dijkstra's algorithm).

-   **Number of Shortest Path Computations**: For a list of `k` required stations, the algorithm needs to calculate the shortest path for `k-1` distinct segments. 
-   **Cost of Each Individual Shortest Path Calculation**: As detailed in the subsequent section, each execution of Dijkstra's algorithm has a worst-case time complexity of $\mathcal{O}((n + m) \log n)$.

Therefore, to arrive at the total worst-case complexity for `multiStageOrderedShortestPath`, we multiply the number of times Dijkstra's algorithm is called by the complexity of a single Dijkstra call, based on the multiplication principle for operations.

**Total Complexity**: $\mathcal{O}((k-1) \cdot \text{Cost of one Dijkstra run}) = \mathcal{O}(k \cdot \mathcal{O}((n + m) \log n)) = \mathcal{O}(k(n + m) \log n)$

**Worst-Case Scenario for `k`**:
It's crucial to consider the most demanding situation for the variable $k$. While $k$ could represent a small, fixed number of required stops (e.g., finding a path through 3 specific cities), in the absolute worst-case scenario, the number of required stations, $k$, could be as large as the total number of stations in the entire graph, $n$. This would happen if, for example, the user wants to visit every single station in the network in a particular order. In this extreme case, where $k \approx n$, the algorithm's complexity would effectively escalate to $\mathcal{O}(n(n + m) \log n)$. This particular upper bound signifies the maximum time this algorithm might ever take if it is required to calculate paths through a significant portion of the entire interconnected network.

---

### 2. Single-Source Dijkstra Algorithm

*This is a foundational and widely recognized algorithm in the field of graph theory. Its primary purpose is to identify the shortest (or least-cost) path from a single designated starting station to all other reachable stations within a network, or specifically to a single target destination. The algorithm operates by iteratively expanding its search, always prioritizing the unvisited station that currently has the minimum known distance from the starting point. To achieve this efficiency, it typically relies on a data structure known as a "min-heap" (a type of priority queue) which allows for very quick retrieval of the closest unvisited station.*

| **CODE** | **ANALYSIS** |
|---|---|
| `function singleSourceDijkstra(graph, start, end)` | **$\mathcal{O}((n + m) \log n)$** |
| `    if start or end not in graph:` | $2C$ |
| `        return null` | $1R$ |
| `    distances = map with all stations set to infinity` | $n A$ |
| `    distances[start] = 0` | $1A$ |
| `    predecessors = empty map` | $1A$ |
| `    priorityQueue = new MinHeap` | $1A$ |
| `    priorityQueue.add(Node(start, 0))` | $1A + \mathcal{O}(\log n)$ |
| `    while priorityQueue is not empty:` | $(n+1)C$ |
| `        current = priorityQueue.poll()` | $n \cdot \mathcal{O}(\log n)$ |
| `        if current.station == end:` | $nC$ |
| `            break` | $1Op$ |
| `        if current.distance > distances[current.station]:` | $nC$ |
| `            continue` | $1Op$ |
| `        for each neighbor in graph[current.station]:` | $\sum_{v \in V} \text{grau}(v) \cdot C = 2m \cdot C$ |
| `            newDistance = current.distance + edge.distance` | $m \cdot (A+Op)$ |
| `            if newDistance < distances[neighbor]:` | $mC$ |
| `                distances[neighbor] = newDistance` | $mA$ |
| `                predecessors[neighbor] = current.station` | $mA$ |
| `                priorityQueue.add(Node(neighbor, newDistance))` | $m \cdot \mathcal{O}(\log n)$ |
| `    path = reconstruct path from predecessors` | $\mathcal{O}(n)$ |
| `    return path if start in path else null` | $1C + 1R$ |

### Dijkstra's Worst-Case Time Complexity

The efficiency of Dijkstra's algorithm, particularly when implemented with a binary min-heap (a data structure optimized for quickly finding and removing the smallest element), is determined by how thoroughly it processes the stations (vertices) and connections (edges) in the graph.

-   **Processing of Stations ($n$)**: The algorithm must, at most, visit and "finalize" each of the $n$ stations exactly once. Each time a station is processed, it involves extracting the station with the smallest current known distance from the priority queue. The cost of extracting the minimum element from a min-heap that might contain up to $n$ elements is proportional to the logarithm of $n$, or $\mathcal{O}(\log n)$. Therefore, the cumulative time spent on processing all stations contributes approximately $\mathcal{O}(n \log n)$ to the total runtime, as described in the analysis of `singleSourceDijkstra`.
-   **Processing of Connections ($m$)**: For every one of the $m$ connections (edges) in the graph, the algorithm might perform an operation called "relaxation." This process involves checking if a newly discovered path to a neighboring station is shorter than any previously known path. If so, the station's distance is updated, and its position in the priority queue might be adjusted (often referred to as a "decrease-key" operation or simply an insertion). The cost of these operations in a binary min-heap is also proportional to the logarithm of $n$, or $\mathcal{O}(\log n)$. Consequently, processing all edges contributes approximately $\mathcal{O}(m \log n)$ to the total runtime.

By combining the time spent on processing both stations and connections (using Theorem 3.3 for sums of functions), the overall worst-case time complexity for Dijkstra's algorithm when using a binary min-heap is:

**Time Complexity**: $\mathcal{O}(n \log n + m \log n) = \mathcal{O}((n + m) \log n)$.

---

## Analysis Conclusion
This section provides a summary of the overall computational efficiency of the shortest route feature, integrating the complexities of its constituent algorithms and outlining its performance characteristics under the most demanding conditions.
The shortest route feature operates by breaking down the problem of traversing a specific sequence of stations into discrete segments. It then computes the shortest path for each of these segments.

-   **Number of Segments**: The number of path segments is directly derived from the number of required stations. For $k$ required stations, there will be $(k - 1)$ segments to compute.
-   **Cost Per Segment**: Each of these segments is independently solved using Dijkstra's algorithm, which, as thoroughly analyzed, has a worst-case time complexity of $\mathcal{O}((n + m) \log n)$.

Therefore, the **Final Total Complexity** for the `multiStageOrderedShortestPath` algorithm, derived from the product of the number of segments and the complexity of each segment (Theorem 3.4), is:

$$\mathcal{O}(k(n + m)\log n)$$

This complexity indicates that the feature's performance scales linearly with the number of specific stations that must be visited ($k$) and logarithmically with the overall size and connectivity of the network ($n$ and $m$). In the **worst-case scenario**, where the ordered list of required stations comprises nearly all stations in the entire network (meaning $k$ is approximately equal to $n$), the overall time complexity would approach $\mathcal{O}(n(n + m)\log n)$. This signifies that the algorithm's runtime is most significantly impacted when operating on very large, interconnected networks that require extensive ordered traversals. However, for graphs that are not excessively dense (i.e., $m$ is relatively small compared to $n^2$) and when the number of required stations ($k$) is a small fraction of the total stations, this algorithm remains a highly efficient solution. This analysis rigorously defines the performance boundaries of the feature, which is essential for informed product development decisions.